---
title: "Log-Log model"
format:
  html:
    code-overflow: wrap
editor: visual
---

## Log_Log Linear Regression Specification and Reproducibility Protocol

To further evaluate the relationship between copper cable theft and its potential predictors, we constructed a log-log linear regression model using the training dataset. The dependent variable was the natural logarithm of the number of copper cable theft cases, and all continuous explanatory variables were also log-transformed to account for potential nonlinear scaling effects and to stabilize variance.

We began with a full model specification that included all lagged explanatory variables identified as Granger-significant in Section 1, as well as dummy variables for the months February through December (January as the reference category):

```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))
```

```{r}
full_model <- lm(log_cases ~ log_Total_theft.lag + log_Copper_price.lag + intervention.lag + log_Unwork_NSW.lag + log_Scrap_Imports_CN.lag + log_t_since.lag + Feb + Mar +  APr + May + Jun + Jul + Aug + Sep + Oct + Nov + Dec, data = train_data)
```

To identify the most parsimonious model, we employed stepwise selection based on the Akaike Information Criterion (AIC). The selected model excluded the December dummy variable:

```{r}
step_model <- step(full_model, direction = "both", trace = FALSE)
summary(step_model)
```

We subsequently refined the model through iterative simplification, removing non-significant variables one by one. The final model (`log_log_model_3`) excluded `log_Unwork_NSW.lag`, `APr` and `Dec` .

```{r}
# Log-log linear regression model (remove Dec)
log_log_model_1 <- lm(log_cases ~ log_Total_theft.lag + log_Copper_price.lag + intervention.lag + log_Unwork_NSW.lag + log_t_since.lag + Mar + APr + May + Jun + Jul + Aug + Sep + Oct + Nov, data = train_data)

# Model summary
summary(log_log_model_1)
```

```{r}
# Log-log linear regression model (remove APr)
log_log_model_2 <- lm(log_cases ~ log_Total_theft.lag + log_Copper_price.lag + intervention.lag + log_Unwork_NSW.lag + log_t_since.lag + Mar + May + Jun + Jul + Aug + Sep + Oct + Nov, data = train_data)

# Model summary
summary(log_log_model_2)
```

```{r}
# Log-log linear regression model (remove log_Unwork_NSW.lag)
log_log_model_3 <- lm(log_cases ~ log_Total_theft.lag + log_Copper_price.lag + intervention.lag + log_t_since.lag + Mar + May + Jun + Jul + Aug + Sep + Oct + Nov, data = train_data)

# Model summary
summary(log_log_model_3)
```

## Model Diagnostics

Comprehensive diagnostic checks were conducted on the residuals of the final model:

-   Normality: The Shapiro–Wilk test and Q–Q plot indicated acceptable normality in residuals.

-   Homoscedasticity: The Breusch–Pagan test did not suggest significant heteroscedasticity.

-   Autocorrelation: The Durbin–Watson and Ljung–Box tests revealed no significant serial correlation.

-   Multicollinearity: Variance Inflation Factors (VIFs) for all retained predictors were below 5, indicating no severe multicollinearity.

Additionally, the residuals were visualized using histograms, residual-vs-fitted plots, ACF, and PACF plots to verify assumptions of OLS regression.

```{r}
# Extract residuals
residuals_log_log_model_3 <- residuals(log_log_model_3)

# Plot residual histogram
hist(residuals_log_log_model_3, breaks = 30, main = "Residuals Histogram", xlab = "Residuals", col = "blue")

# Generate Q–Q plot
qqnorm(residuals_log_log_model_3)
qqline(residuals_log_log_model_3, col = "red")

# Perform Shapiro–Wilk normality test 
shapiro.test(residuals_log_log_model_3)

# Plot residuals vs. fitted values
plot(fitted(log_log_model_3), residuals_log_log_model_3, main = "Residuals vs. Fitted",
     xlab = "Fitted values", ylab = "Residuals", pch = 20, col = "blue")
abline(h = 0, col = "red", lwd = 2)

# Breusch–Pagan test for heteroscedasticity
bptest(log_log_model_3)

# Autocorrelation tests
# Durbin–Watson test
dwtest(log_log_model_3)

# Ljung–Box test
Box.test(residuals_log_log_model_3, lag = 30, type = "Ljung-Box")

# Multicollinearity diagnostics
# Calculate VIF
vif(log_log_model_3)
```

```{r}
library(forecast)
library(ggplot2)

# Extract residuals from the log-log model 
residuals_loglog <- resid(log_log_model_3)

# ACF plot 
acf_loglog_plot <- ggAcf(residuals_loglog, lag.max = 30) +
  labs(
    title = "ACF of Log-Log Model Residuals",
    x = "Lag (Months)",
    y = "Autocorrelation"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    axis.text = element_text(color = "black"),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white", color = NA),
    panel.background = element_rect(fill = "white", color = NA)
  )

# PACF plot 
pacf_loglog_plot <- ggPacf(residuals_loglog, lag.max = 30) +
  labs(
    title = "PACF of Log-Log Model Residuals",
    x = "Lag (Months)",
    y = "Partial Autocorrelation"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    axis.text = element_text(color = "black"),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "white", color = NA),
    panel.background = element_rect(fill = "white", color = NA)
  )

# Display plots 
print(acf_loglog_plot)
print(pacf_loglog_plot)
```

## Out of Sample Prediction and Model Accuracy

Using the final model, we predicted copper cable theft cases on the test dataset. The log-transformed predictions were back-transformed to the original scale using the exponential function minus one, and the predicted values were compared with observed values through a step line cloud with quarterly intervals. Performance matrices were calculated:

-   Mean Error (ME)

-   Root Mean Squared Error (RMSE)

-   Mean Absolute Error (MAE)

-   Mean Percentage Error (MPE)

-   Mean Absolute Percentage Error (MAPE)

-   Mean Absolute Scaled Error (MASE)

-   R-squared (Out-of-sample)

```{r}
# Prediction and back-transformation 
test_data$predicted_log_cases <- predict(log_log_model_3, newdata = test_data)
test_data$predicted_cases <- exp(test_data$predicted_log_cases) - 1
test_data$actual_cases <- test_data$cases  

# Visualization: Predicted vs. Actual Cases (Quarterly) 
ggplot(test_data, aes(x = date)) +
  geom_step(aes(y = actual_cases, color = "Actual Cases"), size = 1.2) +
  geom_step(aes(y = predicted_cases, color = "Predicted Cases"), size = 1.2) +
  scale_color_manual(
    values = c("Actual Cases" = "black",
               "Predicted Cases" = "#00BA38")
  ) +
  scale_x_date(
    date_breaks = "3 months",
    labels = function(x) {
      paste0(format(x, "%Y"), "-Q", lubridate::quarter(x))
    }
  ) +
  scale_y_continuous(
    limits = c(0, 100),
    breaks = seq(0, 100, by = 20)
  ) +
  labs(
    title = "Comparison of Predicted vs. Actual Cases by Quarter",
    x = "Quarter",
    y = "Number of Theft Cases",
    color = "Legend"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10)
  )


# Prediction error evaluation 

# Predict values using the final log-log model
predicted_values <- predict(log_log_model_3, newdata = test_data)

# Back-transform predicted and actual values
predicted_cases <- exp(predicted_values) - 1
test_data$actual_cases <- exp(test_data$log_cases) - 1

# Create result dataframe
prediction_results <- data.frame(
  date = test_data$date,
  actual_cases = test_data$actual_cases,
  predicted_cases = predicted_cases
)

# Compute residuals
errors <- prediction_results$predicted_cases - prediction_results$actual_cases

# Evaluation metrics
ME <- mean(errors)
RMSE <- sqrt(mean(errors^2))
MAE <- mean(abs(errors))
MPE <- mean((errors / prediction_results$actual_cases) * 100)
MAPE <- mean(abs(errors / prediction_results$actual_cases) * 100)

# Naive benchmark for MASE
naive_forecast <- c(NA, head(prediction_results$actual_cases, -1))
naive_errors <- naive_forecast - prediction_results$actual_cases
MASE <- mean(abs(errors)) / mean(abs(naive_errors), na.rm = TRUE)

# R-squared
SSE <- sum((prediction_results$actual_cases - prediction_results$predicted_cases)^2)
SST <- sum((prediction_results$actual_cases - mean(prediction_results$actual_cases))^2)
R_squared <- 1 - SSE / SST

# Output all metrics
cat("Mean Error (ME):", ME, "\n")
cat("Root Mean Squared Error (RMSE):", RMSE, "\n")
cat("Mean Absolute Error (MAE):", MAE, "\n")
cat("Mean Percentage Error (MPE):", MPE, "%\n")
cat("Mean Absolute Percentage Error (MAPE):", MAPE, "%\n")
cat("Mean Absolute Scaled Error (MASE):", MASE, "\n")
cat("R-squared:", round(R_squared, 4), "\n")
```

Last updated: 23 July 2025 Maintainer: \[Hongbo Zhao / Contact: hongbo.zhao\@uqconnect.edu.au\]
